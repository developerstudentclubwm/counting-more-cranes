{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qualitative_analyses.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnCTc7OU60TO"
      },
      "source": [
        "# Qualitative analyses\n",
        "In this notebook, I include all of my qualitative anlayses/results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvBwJeeErZG"
      },
      "source": [
        "## Setup\n",
        "To pull from the GitHub repository in Colab:\n",
        "```\n",
        "%cd drive/MyDrive/Conservation\\ Research/Code/counting-cranes\n",
        "!git add .\n",
        "!git stash\n",
        "!git pull\n",
        "```\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAev1wwGIMY-",
        "outputId": "3af32f30-c017-4aba-e3e8-7dcbaea898d2"
      },
      "source": [
        "#Mounting Google Drive...\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wgebqjk2lqac",
        "outputId": "721ac4e9-4346-47f8-e2ac-3e2db99524ff"
      },
      "source": [
        "#Will have to restart runtime after running this cell!\n",
        "!pip install -r \"/content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.8.1\n",
            "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1 MB 2.7 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1\n",
            "  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 118 kB/s \n",
            "\u001b[?25hCollecting torchtext==0.9.1\n",
            "  Downloading torchtext-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 15.4 MB/s \n",
            "\u001b[?25hCollecting Pillow==8.1.0\n",
            "  Downloading Pillow-8.1.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 25.3 MB/s \n",
            "\u001b[?25hCollecting jupyterlab==1.0.2\n",
            "  Downloading jupyterlab-1.0.2-py2.py3-none-any.whl (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 146 kB/s \n",
            "\u001b[?25hCollecting albumentations==1.0.0\n",
            "  Downloading albumentations-1.0.0-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting numpy==1.20.3\n",
            "  Downloading numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 163 kB/s \n",
            "\u001b[?25hCollecting matplotlib==3.3.4\n",
            "  Downloading matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 12 kB/s \n",
            "\u001b[?25hCollecting pytorch-lightning==1.3.4\n",
            "  Downloading pytorch_lightning-1.3.4-py3-none-any.whl (806 kB)\n",
            "\u001b[K     |████████████████████████████████| 806 kB 35.8 MB/s \n",
            "\u001b[?25hCollecting PyQt5==5.15.4\n",
            "  Downloading PyQt5-5.15.4-cp36.cp37.cp38.cp39-abi3-manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 18.7 MB/s \n",
            "\u001b[?25hCollecting scipy==1.6.3\n",
            "  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 27.4 MB 88 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torchsummary==1.5.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 12)) (1.5.1)\n",
            "Collecting opencv-python==4.5.2.54\n",
            "  Downloading opencv_python-4.5.2.54-cp37-cp37m-manylinux2014_x86_64.whl (51.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 51.0 MB 52 kB/s \n",
            "\u001b[?25hCollecting tifffile==2021.4.8\n",
            "  Downloading tifffile-2021.4.8-py3-none-any.whl (165 kB)\n",
            "\u001b[K     |████████████████████████████████| 165 kB 40.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 3)) (4.41.1)\n",
            "Collecting jupyterlab-server~=1.0.0rc0\n",
            "  Downloading jupyterlab_server-1.0.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: tornado!=6.0.0,!=6.0.1,!=6.0.2 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (5.1.1)\n",
            "Requirement already satisfied: notebook>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (5.3.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.0->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 6)) (3.13)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 64 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==1.0.0->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 6)) (0.16.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 8)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 8)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 8)) (2.4.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (21.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 60.0 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.2.0\n",
            "  Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 48.3 MB/s \n",
            "\u001b[?25hCollecting PyYAML\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 49.8 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.4.0\n",
            "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 43.9 MB/s \n",
            "\u001b[?25hCollecting tensorboard!=2.5.0,>=2.2.0\n",
            "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 44.7 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.0\n",
            "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting PyQt5-Qt5>=5.15\n",
            "  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.9 MB 39 kB/s \n",
            "\u001b[?25hCollecting PyQt5-sip<13,>=12.8\n",
            "  Downloading PyQt5_sip-12.9.0-cp37-cp37m-manylinux1_x86_64.whl (317 kB)\n",
            "\u001b[K     |████████████████████████████████| 317 kB 41.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib==3.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 8)) (1.15.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 48.9 MB/s \n",
            "\u001b[?25hCollecting json5\n",
            "  Downloading json5-0.9.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting jsonschema>=3.0.1\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0rc0->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0rc0->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (21.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0rc0->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (4.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=1.0.0rc0->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (57.2.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (4.10.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (4.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (0.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (5.6.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (5.1.3)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (5.0.5)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (5.3.5)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (1.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (22.1.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.0->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.0->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==1.0.0->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 6)) (2.5.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations==1.0.0->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (1.34.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (0.12.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (1.32.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (1.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (3.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 3)) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.4->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 9)) (3.1.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (0.7.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 47.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 44.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema>=3.0.1->jupyterlab-server~=1.0.0rc0->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (5.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (1.4.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (0.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.3.1->jupyterlab==1.0.2->-r /content/drive/MyDrive/Conservation Research/Code/counting-cranes/requirements.txt (line 5)) (0.5.1)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=0ea8951a44839aec5bdb54ba26397e40c5c6ec0befa705ec276bbd42324f878c\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: jsonschema, multidict, yarl, Pillow, numpy, async-timeout, torch, scipy, matplotlib, json5, fsspec, aiohttp, torchmetrics, tensorboard, PyYAML, PyQt5-sip, PyQt5-Qt5, pyDeprecate, opencv-python-headless, jupyterlab-server, future, torchvision, torchtext, tifffile, pytorch-lightning, PyQt5, opencv-python, jupyterlab, albumentations\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "  Attempting uninstall: tifffile\n",
            "    Found existing installation: tifffile 2021.7.2\n",
            "    Uninstalling tifffile-2021.7.2:\n",
            "      Successfully uninstalled tifffile-2021.7.2\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.20.3 which is incompatible.\n",
            "tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.4.1 which is incompatible.\n",
            "nbclient 0.5.3 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.1.0 PyQt5-5.15.4 PyQt5-Qt5-5.15.2 PyQt5-sip-12.9.0 PyYAML-5.4.1 aiohttp-3.7.4.post0 albumentations-1.0.0 async-timeout-3.0.1 fsspec-2021.7.0 future-0.18.2 json5-0.9.6 jsonschema-3.2.0 jupyterlab-1.0.2 jupyterlab-server-1.0.0 matplotlib-3.3.4 multidict-5.1.0 numpy-1.20.3 opencv-python-4.5.2.54 opencv-python-headless-4.5.3.56 pyDeprecate-0.3.0 pytorch-lightning-1.3.4 scipy-1.6.3 tensorboard-2.4.1 tifffile-2021.4.8 torch-1.8.1 torchmetrics-0.4.1 torchtext-0.9.1 torchvision-0.9.1 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-B7ZpiVS7AE"
      },
      "source": [
        "import json\n",
        "\n",
        "config = json.load(open('/content/drive/MyDrive/Conservation Research/Code/counting-cranes/config.json', 'r'))\n",
        "DATA_FP = config['data_filepath_colab']\n",
        "CODE_FP = config['code_filepath_colab']\n",
        "MODEL_SAVE_FP = config['model_saves_filepath_colab']\n",
        "SEED = config['random_seed']\n",
        "ASPDNET_HYPERPARAMETERS = config['ASPDNet_params']\n",
        "FASTER_RCNN_HYPERPARAMETERS = config['faster_rcnn_params']\n",
        "tile_size = tuple(config['tile_size'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMij68OdS7AF"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(CODE_FP) \n",
        "sys.path.append(os.path.join(CODE_FP, 'density_estimation'))\n",
        "sys.path.append(os.path.join(CODE_FP, 'object_detection'))\n",
        "sys.path.append(os.path.join(CODE_FP, 'density_estimation', 'ASPDNet'))\n",
        "\n",
        "from bird_dataset import *\n",
        "from ASPDNet_model import *\n",
        "from ASPDNet.model import ASPDNet\n",
        "from faster_rcnn_model import *\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_lightning import seed_everything"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ojP5_3h8O68"
      },
      "source": [
        "## General stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBDXNP7IUYUF",
        "outputId": "88bc556e-e725-4187-ac0d-5b9ad2e58afd"
      },
      "source": [
        "#Setting our random seed for all operations (PyTorch, numpy, python.random)\n",
        "seed_everything(SEED);"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 1693\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk9uYB388o3_"
      },
      "source": [
        "#Establishing the datasets/dataloaders\n",
        "bird_dataset_eval_aspdnet = BirdDataset(root_dir = DATA_FP, \n",
        "                                        transforms = get_transforms('density_estimation', train = False), \n",
        "                                        tiling_method = 'w_o_overlap', \n",
        "                                        annotation_mode = 'points', \n",
        "                                        tile_size = tile_size,\n",
        "                                        sigma = 3)\n",
        "bird_dataset_eval_frcnn = BirdDataset(root_dir = DATA_FP, \n",
        "                                      transforms = get_transforms('object_detection', train = False), \n",
        "                                      tiling_method = 'w_o_overlap', \n",
        "                                      tile_size = tile_size) \n",
        "\n",
        "#  recovering the test set\n",
        "indices = torch.randperm(len(bird_dataset_eval_aspdnet)).tolist() #TODO: switch w/the custom permutation once you have the dataset all in order!\n",
        "dataset_test_aspdnet = torch.utils.data.Subset(bird_dataset_eval_aspdnet, indices[28 : ])\n",
        "dataset_test_frcnn = torch.utils.data.Subset(bird_dataset_eval_frcnn, indices[28 : ])\n",
        "\n",
        "#  wrapping datasets in dataloaders\n",
        "dataloader_test_aspdnet = DataLoader(dataset_test_aspdnet, batch_size = ASPDNET_HYPERPARAMETERS['batch_size'], shuffle = False, collate_fn = collate_tiles_density) \n",
        "dataloader_test_frcnn = DataLoader(dataset_test_frcnn, batch_size = FASTER_RCNN_HYPERPARAMETERS['batch_size'], shuffle = False, collate_fn = collate_tiles_object_detection) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUtnHYQU8RBN"
      },
      "source": [
        "#Loading both models\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "#  ASPDnet...\n",
        "save_name = 'ASPDNet_no_neg_densities_200_epochs_7.7.2021.ckpt'\n",
        "aspdnet = ASPDNet().to(device)\n",
        "pl_model_aspdnet = ASPDNetLightning.load_from_checkpoint(os.path.join(MODEL_SAVE_FP, 'ASPDNet', save_name), model = aspdnet)\n",
        "\n",
        "#  Faster R-CNN...\n",
        "save_name = 'model1_6.23.2021.pth'\n",
        "frcnn = get_faster_rcnn(backbone = 'ResNet50', num_classes = 2, **FASTER_RCNN_HYPERPARAMETERS['constructor_hyperparams']).to(device) \n",
        "frcnn.load_state_dict(torch.load(os.path.join(MODEL_SAVE_FP, 'faster_rcnn', '40_epoch_runs', save_name)))\n",
        "pl_model_frcnn = FasterRCNNLightning(model = frcnn)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kVoDqW667e6"
      },
      "source": [
        "## Best/worst tiles\n",
        "Seeing where each model struggles the most.\n",
        "\n",
        "**NOTE: we'll split into negative (use MPE) and non-negative (use MAE) tiles.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4_NMCMv68Y2"
      },
      "source": [
        "#Predict on all test tiles w/both models + save the predicted counts\n",
        "#  - maybe save each tile w/it's true/pred counts in a dict\n",
        "#  - OR we could save the parent img num + tile num and re-extract..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34-o7-w5AQgo"
      },
      "source": [
        "#Predicting on tiles for Faster R-CNN\n",
        "#  When we save the tile results, we need to be able to pull it out of the corresponding BirdDataset subset again...\n",
        "tile_results = {}\n",
        "for i, (tiles, targets, img_fps, annot_fps) in enumerate(dataloader_test_frcnn): #TODO: will probably have to run this w/GPUs enabled!\n",
        "  tiles = [t.to(device) for t in tiles]\n",
        "\n",
        "  pred_counts = pl_model_frcnn.predict_counts(tiles)\n",
        "  true_counts = [len(t['boxes'].tolist()) for t in targets]\n",
        "\n",
        "  for j, (pred, truth) in enumerate(zip(pred_counts, true_counts)):\n",
        "    tile_results[(i, j)] = (pred, truth) #saving pred count, true count for each tile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25io3PLA_0JP"
      },
      "source": [
        "#Calculate MAE/MPE for tiles + pull out the tiles w/the highest/lowest errors\n",
        "#  AS WE HAVE THINGS SET UP: this would be ith parent image in the corrsponding BirdDataset subset and the jth tile in the tiling w/o overlap set"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}